{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bairros_fortaleza = [\n",
    "    \"Aeroporto\", \"Aerolândia\", \"Alagadiço Novo\", \"Aldeota\", \"Alto da Balança\",\n",
    "    \"Álvaro Weyne\", \"Amadeu Furtado\", \"Ancuri\", \"Antônio Bezerra\", \"Autran Nunes\",\n",
    "    \"Barra do Ceará\", \"Barroso\", \"Bela Vista\", \"Benfica\", \"Bom Futuro\",\n",
    "    \"Bom Jardim\", \"Bonsucesso\", \"Cais do Porto\", \"Cajazeiras\", \"Cambeba\",\n",
    "    \"Canindezinho\", \"Carlito Pamplona\", \"Cidade 2000\", \"Cidade dos Funcionários\", \"Coaçu\",\n",
    "    \"Cocó\", \"Conjunto Ceará I\", \"Conjunto Ceará II\", \"Conjunto Esperança\", \"Conjunto Palmeiras\",\n",
    "    \"Couto Fernandes\", \"Cristo Redentor\", \"Curió\", \"Damas\", \"Demócrito Rocha\",\n",
    "    \"Dendê\", \"Dias Macedo\", \"Dionísio Torres\", \"Dom Lustosa\", \"Edson Queiroz\",\n",
    "    \"Ellery\", \"Engenheiro Luciano Cavalcante\", \"Farias Brito\", \"Fátima\", \"Floresta\",\n",
    "    \"Genibaú\", \"Granja Lisboa\", \"Granja Portugal\", \"Guajeru\", \"Guararapes\",\n",
    "    \"Henrique Jorge\", \"Itaoca\", \"Itaperi\", \"Jacarecanga\", \"Jangurussu\",\n",
    "    \"Jardim América\", \"Jardim Cearense\", \"Jardim das Oliveiras\", \"Jardim Guanabara\", \"Jardim Iracema\",\n",
    "    \"João XXIII\", \"Joaquim Távora\", \"Jóquei Clube\", \"José Bonifácio\", \"José de Alencar\",\n",
    "    \"Lagoa Redonda\", \"Manuel Dias Branco\", \"Manoel Sátiro\", \"Maraponga\", \"Messejana\",\n",
    "    \"Meireles\", \"Mondubim\", \"Monte Castelo\", \"Montese\", \"Moura Brasil\",\n",
    "    \"Mucuripe\", \"Panamericano\", \"Papicu\", \"Parangaba\", \"Parque Araxá\",\n",
    "    \"Parque Dois Irmãos\", \"Parque Iracema\", \"Parque Manibura\", \"Parquelândia\", \"Parreão\",\n",
    "    \"Passaré\", \"Paupina\", \"Pedras\", \"Pici\", \"Pirambu\",\n",
    "    \"Planalto Ayrton Senna\", \"Praia de Iracema\", \"Praia do Futuro I\", \"Praia do Futuro II\", \"Prefeito José Walter\",\n",
    "    \"Presidente Kennedy\", \"Presidente Vargas\", \"Quintino Cunha\", \"Rodolfo Teófilo\", \"Sabiaguaba\",\n",
    "    \"Salinas\", \"Santa Rosa\", \"São Bento\", \"São Gerardo\", \"São João do Tauape\",\n",
    "    \"São José\", \"Sapiranga\", \"Serrinha\", \"Siqueira\", \"Varjota\",\n",
    "    \"Vicente Pinzon\", \"Vila Ellery\", \"Vila Peri\", \"Vila União\", \"Vila Velha\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_texto(texto):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', texto)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    ).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bairros_normalizados = [normalizar_texto(bairro) for bairro in bairros_fortaleza]\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_folder = \"../../downloads/Portalnoticiasceara\" \n",
    "dados = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-25/metadata.json\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-26/metadata.json\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(local_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):  # Verificar se é um arquivo JSON\n",
    "            file_path = os.path.join(root, file)\n",
    "            print(f\"Lendo o arquivo: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-25/metadata.json\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-26/metadata.json\n",
      "Dados processados e salvos em ./silver_metadata.json\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(local_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):  # Verificar se é um arquivo JSON\n",
    "            file_path = os.path.join(root, file)\n",
    "            print(f\"Lendo o arquivo: {file_path}\")\n",
    "            try:\n",
    "                # Ler o conteúdo do arquivo JSON\n",
    "                with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "                    json_data = json.load(json_file)\n",
    "                \n",
    "                # Verificar se o conteúdo do JSON é uma lista\n",
    "                if isinstance(json_data, list):\n",
    "                    for item in json_data:\n",
    "                        # Extrair informações relevantes\n",
    "                        message = item.get('message', '')\n",
    "                        message_id = item.get('id', None)\n",
    "                        date = item.get('date', None)\n",
    "                        media_path = item.get('media_path', None)\n",
    "                        \n",
    "                        if message:\n",
    "                            # Normalizar a mensagem\n",
    "                            message_normalizada = normalizar_texto(message)\n",
    "                            \n",
    "                            # Identificar bairros mencionados\n",
    "                            bairros_mencionados = [\n",
    "                                bairro_original for bairro_original, bairro_normalizado in zip(bairros_fortaleza, bairros_normalizados)\n",
    "                                if bairro_normalizado in message_normalizada\n",
    "                            ]\n",
    "                            \n",
    "                            # Se algum bairro foi identificado, salvar os dados\n",
    "                            if bairros_mencionados:\n",
    "                                for bairro in bairros_mencionados:\n",
    "                                    dados.append({\n",
    "                                        \"id\": message_id,\n",
    "                                        \"mensagem\": message,\n",
    "                                        \"bairro\": bairro,\n",
    "                                        \"data\": date,\n",
    "                                        \"media_path\": media_path\n",
    "                                    })\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar {file_path}: {e}\")\n",
    "\n",
    "# Salvar os dados extraídos em um novo arquivo JSON\n",
    "output_file = './silver_metadata.json'\n",
    "with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(dados, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Dados processados e salvos em {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupado por Bairro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agrupado_por_bairro = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-25/metadata.json\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-26/metadata.json\n",
      "Arquivo criado para Planalto Ayrton Senna: ./outputs/Planalto Ayrton Senna.json\n",
      "Arquivo criado para Pici: ./outputs/Pici.json\n",
      "Arquivo criado para Barra do Ceará: ./outputs/Barra do Ceará.json\n",
      "Arquivo criado para Cristo Redentor: ./outputs/Cristo Redentor.json\n",
      "Arquivo criado para Cajazeiras: ./outputs/Cajazeiras.json\n",
      "Arquivo criado para Jangurussu: ./outputs/Jangurussu.json\n",
      "Arquivo criado para Presidente Vargas: ./outputs/Presidente Vargas.json\n",
      "Arquivo criado para Bom Jardim: ./outputs/Bom Jardim.json\n",
      "Arquivo criado para Carlito Pamplona: ./outputs/Carlito Pamplona.json\n",
      "Arquivo criado para Quintino Cunha: ./outputs/Quintino Cunha.json\n",
      "Arquivo criado para Messejana: ./outputs/Messejana.json\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(local_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):  # Verificar se é um arquivo JSON\n",
    "            file_path = os.path.join(root, file)\n",
    "            print(f\"Lendo o arquivo: {file_path}\")\n",
    "            try:\n",
    "                # Ler o conteúdo do arquivo JSON\n",
    "                with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "                    json_data = json.load(json_file)\n",
    "                \n",
    "                # Verificar se o conteúdo do JSON é uma lista\n",
    "                if isinstance(json_data, list):\n",
    "                    for item in json_data:\n",
    "                        # Extrair informações relevantes\n",
    "                        message = item.get('message', '')\n",
    "                        message_id = item.get('id', None)\n",
    "                        date = item.get('date', None)\n",
    "                        media_path = item.get('media_path', None)\n",
    "                        \n",
    "                        if message:\n",
    "                            # Normalizar a mensagem\n",
    "                            message_normalizada = normalizar_texto(message)\n",
    "                            \n",
    "                            # Identificar bairros mencionados\n",
    "                            bairros_mencionados = [\n",
    "                                bairro_original for bairro_original, bairro_normalizado in zip(bairros_fortaleza, bairros_normalizados)\n",
    "                                if bairro_normalizado in message_normalizada\n",
    "                            ]\n",
    "                            \n",
    "                            # Se algum bairro foi identificado, salvar os dados agrupados\n",
    "                            for bairro in bairros_mencionados:\n",
    "                                if bairro not in agrupado_por_bairro:\n",
    "                                    agrupado_por_bairro[bairro] = []  # Inicializa a lista para o bairro\n",
    "                                \n",
    "                                # Verifica se a mensagem já está no agrupamento para evitar duplicação\n",
    "                                mensagem_existente = any(\n",
    "                                    mensagem['id'] == message_id and mensagem['mensagem'] == message \n",
    "                                    for mensagem in agrupado_por_bairro[bairro]\n",
    "                                )\n",
    "                                \n",
    "                                if not mensagem_existente:\n",
    "                                    agrupado_por_bairro[bairro].append({\n",
    "                                        \"id\": message_id,\n",
    "                                        \"mensagem\": message,\n",
    "                                        \"data\": date,\n",
    "                                        \"media_path\": media_path\n",
    "                                    })\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar {file_path}: {e}\")\n",
    "\n",
    "# Criar um arquivo JSON separado para cada bairro\n",
    "output_folder = \"./outputs\"  # Pasta para salvar os arquivos\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for bairro, mensagens in agrupado_por_bairro.items():\n",
    "    output_file = os.path.join(output_folder, f\"{bairro}.json\")\n",
    "    with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(mensagens, json_file, ensure_ascii=False, indent=4)\n",
    "    print(f\"Arquivo criado para {bairro}: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
