{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bairros_fortaleza = [\n",
    "    \"aeroporto\", \"aerolandia\", \"alagadico_novo\", \"aldeota\", \"alto_da_balanca\",\n",
    "    \"alvaro_weyne\", \"amadeu_furtado\", \"ancuri\", \"antonio_bezerra\", \"autran_nunes\",\n",
    "    \"barra_do_ceara\", \"barroso\", \"bela_vista\", \"benfica\", \"bom_futuro\",\n",
    "    \"bom_jardim\", \"bonsucesso\", \"cais_do_porto\", \"cajazeiras\", \"cambeba\",\n",
    "    \"canindezinho\", \"carlito_pamplona\", \"cidade_2000\", \"cidade_dos_funcionarios\", \"coaçu\",\n",
    "    \"coco\", \"conjunto_ceara_i\", \"conjunto_ceara_ii\", \"conjunto_esperanca\", \"conjunto_palmeiras\",\n",
    "    \"couto_fernandes\", \"cristo_redentor\", \"curio\", \"damas\", \"democrito_rocha\",\n",
    "    \"dende\", \"dias_macedo\", \"dionisio_torres\", \"dom_lustosa\", \"edson_queiroz\",\n",
    "    \"ellery\", \"engenheiro_luciano_cavalcante\", \"farias_brito\", \"fatima\", \"floresta\",\n",
    "    \"genibau\", \"granja_lisboa\", \"granja_portugal\", \"guajeru\", \"guararapes\",\n",
    "    \"henrique_jorge\", \"itaoca\", \"itaperi\", \"jacarecanga\", \"jangurussu\",\n",
    "    \"jardim_america\", \"jardim_cearense\", \"jardim_das_oliveiras\", \"jardim_guanabara\", \"jardim_iracema\",\n",
    "    \"joao_xxiii\", \"joaquim_tavora\", \"joquei_clube\", \"jose_bonifacio\", \"jose_de_alencar\",\n",
    "    \"lagoa_redonda\", \"manuel_dias_branco\", \"manoel_satiro\", \"maraponga\", \"messejana\",\n",
    "    \"meireles\", \"mondubim\", \"monte_castelo\", \"montese\", \"moura_brasil\",\n",
    "    \"mucuripe\", \"panamericano\", \"papicu\", \"parangaba\", \"parque_araxa\",\n",
    "    \"parque_dois_irmaos\", \"parque_iracema\", \"parque_manibura\", \"parquelandia\", \"parreao\",\n",
    "    \"passare\", \"paupina\", \"pedras\", \"pici\", \"pirambu\",\n",
    "    \"planalto_ayrton_senna\", \"praia_de_iracema\", \"praia_do_futuro_i\", \"praia_do_futuro_ii\", \"prefeito_jose_walter\",\n",
    "    \"presidente_kennedy\", \"presidente_vargas\", \"quintino_cunha\", \"rodolfo_teofilo\", \"sabiaguaba\",\n",
    "    \"salinas\", \"santa_rosa\", \"sao_bento\", \"sao_gerardo\", \"sao_joao_do_tauape\",\n",
    "    \"sao_jose\", \"sapiranga\", \"serrinha\", \"siqueira\", \"varjota\",\n",
    "    \"vicente_pinzon\", \"vila_ellery\", \"vila_peri\", \"vila_uniao\", \"vila_velha\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_texto(texto):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', texto)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    ).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bairros_normalizados = [normalizar_texto(bairro) for bairro in bairros_fortaleza]\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_folder = \"../../downloads/Portalnoticiasceara\" \n",
    "dados = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-15/metadata.json\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-17/metadata.json\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-18/metadata.json\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-14/metadata.json\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-19/metadata.json\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-13/metadata.json\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-16/metadata.json\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-26/metadata.json\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-27/metadata.json\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(local_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):  # Verificar se é um arquivo JSON\n",
    "            file_path = os.path.join(root, file)\n",
    "            print(f\"Lendo o arquivo: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "def verificar_ultimas_24_horas(data_msg):\n",
    "    try:\n",
    "        # Converter a data da mensagem para datetime com fuso horário UTC (aware datetime)\n",
    "        data_msg = datetime.fromisoformat(data_msg.replace(\"Z\", \"+00:00\"))  # Ajuste para o formato ISO 8601\n",
    "        \n",
    "        # Obter a data e hora atuais com fuso horário UTC (aware datetime)\n",
    "        agora = datetime.now(timezone.utc)\n",
    "        \n",
    "        # Calcular a diferença de tempo\n",
    "        diff = agora - data_msg\n",
    "        return diff <= timedelta(hours=24)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar a data: {e}\")\n",
    "        return False\n",
    "    \n",
    "\n",
    "def verificar_ultimos_7_dias(data_msg):\n",
    "    try:\n",
    "        # Converter a data da mensagem para datetime com fuso horário UTC (aware datetime)\n",
    "        data_msg = datetime.fromisoformat(data_msg.replace(\"Z\", \"+00:00\"))  # Ajuste para o formato ISO 8601\n",
    "        \n",
    "        # Obter a data e hora atuais com fuso horário UTC (aware datetime)\n",
    "        agora = datetime.now(timezone.utc)\n",
    "        \n",
    "        # Calcular a diferença de tempo\n",
    "        diff = agora - data_msg\n",
    "        return diff <= timedelta(days=7)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar a data: {e}\")\n",
    "        return False\n",
    "    \n",
    "\n",
    "def verificar_ultimo_mes(data_msg):\n",
    "    try:\n",
    "        # Converter a data da mensagem para datetime com fuso horário UTC (aware datetime)\n",
    "        data_msg = datetime.fromisoformat(data_msg.replace(\"Z\", \"+00:00\"))  # Ajuste para o formato ISO 8601\n",
    "        \n",
    "        # Obter a data e hora atuais com fuso horário UTC (aware datetime)\n",
    "        agora = datetime.now(timezone.utc)\n",
    "        \n",
    "        # Calcular a diferença de tempo\n",
    "        diff = agora - data_msg\n",
    "        return diff <= timedelta(days=30)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar a data: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerando função dinamica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_file(nome_arquivo, funcao_offset):\n",
    "    ids_processados = set()\n",
    "    for root, dirs, files in os.walk(local_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):  # Verificar se é um arquivo JSON\n",
    "                file_path = os.path.join(root, file)\n",
    "                print(f\"Lendo o arquivo: {file_path}\")\n",
    "                try:\n",
    "                    # Ler o conteúdo do arquivo JSON\n",
    "                    with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "                        json_data = json.load(json_file)\n",
    "                    \n",
    "                    # Iterar sobre os itens da lista (cada item é uma mensagem)\n",
    "                    for message_data in json_data:\n",
    "                        # Extrair os dados necessários do JSON\n",
    "                        message = message_data.get('message', '')\n",
    "                        date = message_data.get('date', None)\n",
    "                        media_path = message_data.get('media_path', None)\n",
    "                        message_id = message_data.get('id', '')\n",
    "\n",
    "                        # Verificar se o ID já foi processado ou se dados são inválidos\n",
    "                        if not message or not date or not message_id:\n",
    "                            continue\n",
    "                        if message_id in ids_processados:\n",
    "                            continue\n",
    "                        if not funcao_offset(date):\n",
    "                            continue\n",
    "\n",
    "                        # Normalizar a mensagem\n",
    "                        message_normalizada = normalizar_texto(message)\n",
    "                        \n",
    "                        # Identificar bairros mencionados na mensagem\n",
    "                        bairros_mencionados = [\n",
    "                            bairro_original for bairro_original, bairro_normalizado in zip(bairros_fortaleza, bairros_normalizados)\n",
    "                            if bairro_normalizado in message_normalizada\n",
    "                        ]\n",
    "                        \n",
    "                        # Se algum bairro foi identificado, salvar apenas o primeiro bairro\n",
    "                        if bairros_mencionados:\n",
    "                            primeiro_bairro = bairros_mencionados[0]\n",
    "                            dados.append({\n",
    "                                \"id\": message_id,\n",
    "                                \"mensagem\": message,\n",
    "                                \"bairro\": primeiro_bairro,\n",
    "                                \"data\": date,\n",
    "                                \"media_path\": media_path\n",
    "                            })\n",
    "                            ids_processados.add(message_id)  # Marcar o ID como processado\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao processar {file_path}: {e}\")\n",
    "\n",
    "    # Salvar os dados extraídos em um novo arquivo JSON\n",
    "    output_folder = f\"./{nome_arquivo}\"  \n",
    "    output_file = os.path.join(output_folder, f'{nome_arquivo}.json')\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(dados, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"Dados processados e salvos em {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-15/metadata.json\n",
      "Erro ao processar ../../downloads/Portalnoticiasceara/2024-12-15/metadata.json: 'str' object has no attribute 'get'\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-17/metadata.json\n",
      "Erro ao processar ../../downloads/Portalnoticiasceara/2024-12-17/metadata.json: 'str' object has no attribute 'get'\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-18/metadata.json\n",
      "Erro ao processar ../../downloads/Portalnoticiasceara/2024-12-18/metadata.json: 'str' object has no attribute 'get'\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-14/metadata.json\n",
      "Erro ao processar ../../downloads/Portalnoticiasceara/2024-12-14/metadata.json: 'str' object has no attribute 'get'\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-19/metadata.json\n",
      "Erro ao processar ../../downloads/Portalnoticiasceara/2024-12-19/metadata.json: 'str' object has no attribute 'get'\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-13/metadata.json\n",
      "Erro ao processar ../../downloads/Portalnoticiasceara/2024-12-13/metadata.json: 'str' object has no attribute 'get'\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-16/metadata.json\n",
      "Erro ao processar ../../downloads/Portalnoticiasceara/2024-12-16/metadata.json: 'str' object has no attribute 'get'\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-26/metadata.json\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-27/metadata.json\n",
      "Dados processados e salvos em ./noticias_recentes/noticias_recentes.json\n"
     ]
    }
   ],
   "source": [
    "create_json_file('noticias_recentes', verificar_ultimas_24_horas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupado por Bairro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_agg_bairro():\n",
    "    agrupado_por_bairro = {}\n",
    "    for root, dirs, files in os.walk(local_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):  # Verificar se é um arquivo JSON\n",
    "                file_path = os.path.join(root, file)\n",
    "                print(f\"Lendo o arquivo: {file_path}\")\n",
    "                try:\n",
    "                    # Ler o conteúdo do arquivo JSON\n",
    "                    with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "                        json_data = json.load(json_file)\n",
    "                    \n",
    "                    # Iterar sobre os itens do dicionário (cada chave é um ID de mensagem)\n",
    "                    for message_id, message_data in json_data.items():\n",
    "                        # Extrair os dados necessários\n",
    "                        message = message_data.get('message', '')\n",
    "                        date = message_data.get('date', None)\n",
    "                        media_path = message_data.get('media_path', None)\n",
    "                        \n",
    "                        if message:\n",
    "                            # Normalizar a mensagem\n",
    "                            message_normalizada = normalizar_texto(message)\n",
    "                            \n",
    "                            # Identificar bairros mencionados na mensagem\n",
    "                            bairros_mencionados = [\n",
    "                                bairro_original for bairro_original, bairro_normalizado in zip(bairros_fortaleza, bairros_normalizados)\n",
    "                                if bairro_normalizado in message_normalizada\n",
    "                            ]\n",
    "                            \n",
    "                            # Se algum bairro foi identificado, salvar os dados agrupados\n",
    "                            for bairro in bairros_mencionados:\n",
    "                                if bairro not in agrupado_por_bairro:\n",
    "                                    agrupado_por_bairro[bairro] = []  # Inicializa a lista para o bairro\n",
    "                                \n",
    "                                # Verifica se a mensagem já está no agrupamento para evitar duplicação\n",
    "                                mensagem_existente = any(\n",
    "                                    mensagem['id'] == message_id and mensagem['mensagem'] == message \n",
    "                                    for mensagem in agrupado_por_bairro[bairro]\n",
    "                                )\n",
    "                                \n",
    "                                if not mensagem_existente:\n",
    "                                    agrupado_por_bairro[bairro].append({\n",
    "                                        \"id\": message_id,\n",
    "                                        \"mensagem\": message,\n",
    "                                        \"data\": date,\n",
    "                                        \"media_path\": media_path\n",
    "                                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao processar {file_path}: {e}\")\n",
    "\n",
    "    # Criar um arquivo JSON separado para cada bairro\n",
    "    output_folder = \"../data/ceara/fortaleza/bairros\"  # Pasta para salvar os arquivos\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for bairro, mensagens in agrupado_por_bairro.items():\n",
    "        output_file = os.path.join(output_folder, f\"{bairro}.json\")\n",
    "        with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "            json.dump(mensagens, json_file, ensure_ascii=False, indent=4)\n",
    "        print(f\"Arquivo criado para {bairro}: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-15/metadata.json\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-17/metadata.json\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-18/metadata.json\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-14/metadata.json\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-19/metadata.json\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-13/metadata.json\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-16/metadata.json\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-26/metadata.json\n",
      "Erro ao processar ../../downloads/Portalnoticiasceara/2024-12-26/metadata.json: 'list' object has no attribute 'items'\n",
      "Lendo o arquivo: ../../downloads/Portalnoticiasceara/2024-12-27/metadata.json\n",
      "Erro ao processar ../../downloads/Portalnoticiasceara/2024-12-27/metadata.json: 'list' object has no attribute 'items'\n",
      "Arquivo criado para dende: ../data/ceara/fortaleza/bairros/dende.json\n",
      "Arquivo criado para coco: ../data/ceara/fortaleza/bairros/coco.json\n",
      "Arquivo criado para serrinha: ../data/ceara/fortaleza/bairros/serrinha.json\n",
      "Arquivo criado para barroso: ../data/ceara/fortaleza/bairros/barroso.json\n",
      "Arquivo criado para pedras: ../data/ceara/fortaleza/bairros/pedras.json\n",
      "Arquivo criado para mondubim: ../data/ceara/fortaleza/bairros/mondubim.json\n",
      "Arquivo criado para passare: ../data/ceara/fortaleza/bairros/passare.json\n",
      "Arquivo criado para varjota: ../data/ceara/fortaleza/bairros/varjota.json\n",
      "Arquivo criado para jangurussu: ../data/ceara/fortaleza/bairros/jangurussu.json\n",
      "Arquivo criado para pici: ../data/ceara/fortaleza/bairros/pici.json\n",
      "Arquivo criado para aerolandia: ../data/ceara/fortaleza/bairros/aerolandia.json\n",
      "Arquivo criado para pirambu: ../data/ceara/fortaleza/bairros/pirambu.json\n",
      "Arquivo criado para messejana: ../data/ceara/fortaleza/bairros/messejana.json\n",
      "Arquivo criado para cajazeiras: ../data/ceara/fortaleza/bairros/cajazeiras.json\n",
      "Arquivo criado para sapiranga: ../data/ceara/fortaleza/bairros/sapiranga.json\n"
     ]
    }
   ],
   "source": [
    "create_json_agg_bairro()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
